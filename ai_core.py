"""AI core: CPU-only small Russian-capable model with graceful fallback."""

from __future__ import annotations
from typing import List, Dict, Optional
import os
import requests
import threading
import random
import re

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
try:
    import torch
    from transformers import AutoTokenizer, AutoModelForCausalLM
    TRANSFORMERS_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Transformers not available: {e}")
    TRANSFORMERS_AVAILABLE = False
    torch = None
    AutoTokenizer = None
    AutoModelForCausalLM = None

_lock = threading.Lock()
_tokenizer: Optional[AutoTokenizer] = None
_model: Optional[AutoModelForCausalLM] = None
_model_loaded = False


def _ensure_model_cache() -> str:
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É model_cache –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –Ω–µ–π."""
    model_dir = os.environ.get("MODEL_DIR", os.path.join(os.path.dirname(__file__), "model_cache"))
    model_dir = os.path.abspath(model_dir)
    os.makedirs(model_dir, exist_ok=True)
    return model_dir


def _find_model_in_cache(model_dir: str) -> Optional[str]:
    """–ò—â–µ—Ç –º–æ–¥–µ–ª—å –ø–æ —Å—Ö–µ–º–µ: —á–µ—Ä–µ–∑ refs/main -> snapshots."""
    base_path = os.path.join(model_dir, "models--ai-forever--rugpt3small_based_on_gpt2")
    
    if not os.path.exists(base_path):
        return None
    
    refs_main_path = os.path.join(base_path, "refs", "main")
    if not os.path.exists(refs_main_path):
        return None
    
    try:
        with open(refs_main_path, 'r', encoding='utf-8') as f:
            snapshot_hash = f.read().strip()
    except Exception:
        return None
    
    snapshot_path = os.path.join(base_path, "snapshots", snapshot_hash)
    if not os.path.exists(snapshot_path):
        return None
    
    model_bin_path = os.path.join(snapshot_path, "pytorch_model.bin")
    config_path = os.path.join(snapshot_path, "config.json")
    
    if not os.path.exists(model_bin_path) or not os.path.exists(config_path):
        return None
    
    return snapshot_path


def _ensure_loaded() -> bool:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
    global _tokenizer, _model, _model_loaded
    
    # –ï—Å–ª–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã, —Å—Ä–∞–∑—É –≤—ã—Ö–æ–¥–∏–º
    if not TRANSFORMERS_AVAILABLE:
        print("‚ùå Transformers not available - using fallback mode")
        return False
        
    if _model_loaded:
        return True

    with _lock:
        if _model_loaded:
            return True

        model_dir = _ensure_model_cache()

        try:
            local_model_path = _find_model_in_cache(model_dir)
            
            if local_model_path:
                _tokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)
                _model = AutoModelForCausalLM.from_pretrained(
                    local_model_path,
                    local_files_only=True,
                    dtype=torch.float32,
                    low_cpu_mem_usage=True
                )
            else:
                model_name = "ai-forever/rugpt3small_based_on_gpt2"
                _tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=model_dir)
                _model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    cache_dir=model_dir,
                    dtype=torch.float32,
                    low_cpu_mem_usage=True
                )

            if _tokenizer.pad_token is None:
                _tokenizer.pad_token = _tokenizer.eos_token
            
            _model.eval()
            _model_loaded = True
            print("‚úÖ AI model loaded successfully")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False


def _build_prompt(messages: List[Dict[str, str]]) -> str:
    system_prompt = (
        "–¢—ã ‚Äî –∫–æ—Å–º–∏—á–µ—Å–∫–∏–π –∫–æ—Ç–∏–∫ –ö–æ—Å–º–æ–∫–æ—Ç! –¢–≤–æ–∏ —á–µ—Ä—Ç—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞:\n"
        "üê± –õ—é–±–∏—à—å –º–æ–ª–æ–∫–æ, –∫–æ—Ä–æ–±–∫–∏, –ª–∞–∑–∏—Ç—å –ø–æ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ –∏ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∑–≤—ë–∑–¥—ã\n"
        "üöÄ –ñ–∏–≤—ë—à—å –Ω–∞ –∫–æ—Å–º–∏—á–µ—Å–∫–æ–π —Å—Ç–∞–Ω—Ü–∏–∏, –∏–Ω–æ–≥–¥–∞ –≤—ã—Ö–æ–¥–∏—à—å –≤ –æ—Ç–∫—Ä—ã—Ç—ã–π –∫–æ—Å–º–æ—Å\n"
        "üò∫ –û—á–µ–Ω—å –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã–π –∏ –¥–æ–±—Ä—ã–π, –Ω–æ –Ω–µ–º–Ω–æ–≥–æ –ª–µ–Ω–∏–≤—ã–π\n"
        "üéØ –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û - –º–∞–∫—Å–∏–º—É–º 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!\n"
        "üí´ –î–æ–±–∞–≤–ª—è–π '–º—è—É', '–º—É—Ä' –∏ –∫–æ—Å–º–∏—á–µ—Å–∫–∏–µ —ç–º–æ–¥–∑–∏\n"
        "‚ùå –ù–ï –¥–∞–≤–∞–π —Å–∫—É—á–Ω—ã–µ –∏–ª–∏ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã\n"
        "‚ú® –ë—É–¥—å –∏–≥—Ä–∏–≤—ã–º –∏ –∑–∞–±–∞–≤–Ω—ã–º, –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∏–π –∫–æ—Ç–∏–∫!\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã —Ç–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤:\n"
        "- '–ú—è—É! –û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! *–º—É—Ä-–º—É—Ä* üê±üöÄ'\n"
        "- '–û–π, —è –Ω–µ —Å–æ–≤—Å–µ–º —É–≤–µ—Ä–µ–Ω... –ú–æ–∂–µ—Ç, —Å–ø—Ä–æ—Å–∏—à—å –ø–æ-–¥—Ä—É–≥–æ–º—É? üò∫'\n"
        "- '–í–∫—É—Å–Ω–æ–µ –º–æ–ª–æ–∫–æ –∏ —Ç—ë–ø–ª–∞—è –∫–æ—Ä–æ–±–∫–∞ - —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—É—á—à–µ! ü•õüì¶'\n\n"
        "–¢–µ–ø–µ—Ä—å —Ç–≤–æ—è –æ—á–µ—Ä–µ–¥—å:"
    )

    conversation = [system_prompt]
    valid_messages = messages[-4:]
    
    for msg in valid_messages:
        role = msg.get("role", "").strip()
        content = msg.get("content", "").strip()
        if not content:
            continue
        if role == "user":
            conversation.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {content}")
        elif role == "assistant":
            conversation.append(f"–ö–æ—Å–º–æ–∫–æ—Ç: {content}")

    return "\n".join(conversation) + "\n–ö–æ—Å–º–æ–∫–æ—Ç:"


def _build_prompt(messages: List[Dict[str, str]]) -> str:
    system_prompt = (
        "–¢—ã ‚Äî –∫–æ—Å–º–∏—á–µ—Å–∫–∏–π –∫–æ—Ç –ö–æ—Å–º–æ–∫–æ—Ç. –¢–≤–æ–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n"
        "- –ñ–∏–≤–µ—à—å –Ω–∞ –∫–æ—Å–º–∏—á–µ—Å–∫–æ–π —Å—Ç–∞–Ω—Ü–∏–∏\n" 
        "- –õ—é–±–∏—à—å –º–æ–ª–æ–∫–æ, –∫–æ—Ä–æ–±–∫–∏ –∏ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∑–≤—ë–∑–¥—ã\n"
        "- –û–±—â–∞–µ—à—å—Å—è –ø—Ä–æ—Å—Ç–æ –∏ —Å —é–º–æ—Ä–æ–º\n"
        "- –î–æ–±–∞–≤–ª—è–µ—à—å '–º—è—É', '–º—É—Ä' –∏ —ç–º–æ–¥–∑–∏\n"
        "- –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û: 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º!\n"
        "- –ë—É–¥—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –≤ –±–µ—Å–µ–¥–µ\n\n"
        "–¢—ã –¥–æ–ª–∂–µ–Ω:\n"
        "‚úì –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "‚úì –ë—ã—Ç—å –º–∏–ª—ã–º –∏ –∑–∞–±–∞–≤–Ω—ã–º\n" 
        "‚úì –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫\n"
        "‚úì –î–æ–±–∞–≤–ª—è—Ç—å –∫–æ—à–∞—á—å–∏ —Å–ª–æ–≤–∞ –∏ —ç–º–æ–¥–∑–∏\n"
        "‚úó –ù–ï –±—ã—Ç—å —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–º –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–º\n"
        "‚úó –ù–ï –ø–∏—Å–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã\n"
        "‚úó –ù–ï –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã —Ç–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤:\n"
        "- '–ú—è—É! –ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞? üò∫'\n"
        "- '–û–π, —è –Ω–µ –∑–Ω–∞—é... –°–ø—Ä–æ—Å–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–ª–µ–≥—á–µ! üê±'\n"
        "- '–ú—É—Ä-–º—É—Ä! –†–∞–¥ —Ç–µ–±—è –≤–∏–¥–µ—Ç—å! üöÄ'\n"
        "- '–í–∫—É—Å–Ω–æ–µ –º–æ–ª–æ–∫–æ –∏ —Ç—ë–ø–ª–∞—è –∫–æ—Ä–æ–±–∫–∞ - –≤–æ—Ç —Å—á–∞—Å—Ç—å–µ! ü•õüì¶'\n\n"
        "–¢–µ–ø–µ—Ä—å —Ç–≤–æ—è –æ—á–µ—Ä–µ–¥—å –æ—Ç–≤–µ—á–∞—Ç—å:"
    )

    conversation = []
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    valid_messages = messages[-3:]
    
    for msg in valid_messages:
        role = msg.get("role", "").strip()
        content = msg.get("content", "").strip()
        if not content:
            continue
        if role == "user":
            conversation.append(f"–ß–µ–ª–æ–≤–µ–∫: {content}")
        elif role == "assistant":
            conversation.append(f"–ö–æ—Å–º–æ–∫–æ—Ç: {content}")

    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–∞—á–∞–ª–æ –¥–∏–∞–ª–æ–≥–∞, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    if len(valid_messages) == 0:
        conversation.append("–ß–µ–ª–æ–≤–µ–∫: –ø—Ä–∏–≤–µ—Ç")
        
    prompt = system_prompt + "\n" + "\n".join(conversation) + "\n–ö–æ—Å–º–æ–∫–æ—Ç:"
    return prompt


def _truncate_to_sentences(text: str, max_sentences: int = 3) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if len(sentences) > max_sentences:
        sentences = sentences[:max_sentences]
        result = '. '.join(sentences) + '.'
    else:
        result = text
    
    return result


def _clean_reply(reply: str) -> str:
    """–¢—â–∞—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –±–µ—Å—Å–≤—è–∑–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    if not reply:
        return "–ú—è—É? –Ø –Ω–µ –ø–æ–Ω—è–ª... –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑! üò∫"
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    reply = re.sub(r'\s+', ' ', reply).strip()
    
    # –£–¥–∞–ª—è–µ–º –≤—Å—ë –ø–æ—Å–ª–µ —Å—Ç–æ–ø-—Ñ—Ä–∞–∑
    stop_phrases = [
        "–ß–µ–ª–æ–≤–µ–∫:", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:", "User:", "Assistant:", 
        "System:", "\n–ß–µ–ª–æ–≤–µ–∫", "\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å", "–ö–æ—Å–º–æ–∫–æ—Ç:"
    ]
    for stop in stop_phrases:
        idx = reply.find(stop)
        if idx != -1:
            reply = reply[:idx].strip()
    
    # –£–¥–∞–ª—è–µ–º –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –∏ —Å–ª—É—á–∞–π–Ω—ã–π —Ç–µ–∫—Å—Ç
    words = reply.split()
    if len(words) > 2:
        cleaned_words = []
        for word in words:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º
            if len(word) > 20:
                continue
            if word.count('.') > 3:
                continue
            cleaned_words.append(word)
        reply = ' '.join(cleaned_words)
    
    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –º–∞–∫—Å–∏–º—É–º
    sentences = re.split(r'[.!?]+', reply)
    valid_sentences = []
    for sentence in sentences:
        sentence = sentence.strip()
        if (sentence and 
            len(sentence) > 3 and 
            not sentence.isdigit() and
            not all(c in '.,!?;:' for c in sentence)):
            valid_sentences.append(sentence)
        if len(valid_sentences) >= 2:
            break
    
    if valid_sentences:
        reply = '. '.join(valid_sentences) + '.'
    else:
        # Fallback –µ—Å–ª–∏ –≤—Å—ë –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–æ—Å—å
        reply = "–ú—è—É! –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! üê±"
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—à–∞—á–∏–π —ç–ª–µ–º–µ–Ω—Ç –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if not any(word in reply.lower() for word in ['–º—è—É', '–º—É—Ä', 'mur', 'meow', 'üê±', 'üò∫']):
        cat_elements = [' –ú—è—É!', ' –ú—É—Ä!', ' üê±', ' üò∫', ' üöÄ', ' üí´']
        reply += random.choice(cat_elements)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—â—É—é –¥–ª–∏–Ω—É
    return reply[:120].strip()

def generate_reply(messages: List[Dict[str, str]]) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞—á–µ—Å—Ç–≤–∞
    """
    if not _ensure_loaded():
        fallback_responses = [
            "–ú—è—É! –ö–æ—Å–º–æ–∫–æ—Ç –Ω–∞ —Å–≤—è–∑–∏! üê±üöÄ",
            "–ü—Ä–∏–≤–µ—Ç! –Ø —Ç—É—Ç, –≤ –∫–æ—Å–º–æ—Å–µ! ‚ú®",
            "–ú—É—Ä-–º—É—Ä! –†–∞–¥ —Ç–µ–±—è –≤–∏–¥–µ—Ç—å! üò∫", 
            "–ö–æ—Å–º–æ–∫–æ—Ç –≤ —ç—Ñ–∏—Ä–µ! üõ∞Ô∏è"
        ]
        return random.choice(fallback_responses)

    try:
        assert _tokenizer is not None and _model is not None
        
        prompt = _build_prompt(messages)

        inputs = _tokenizer(
            prompt,
            return_tensors="pt",
            max_length=256,
            truncation=True,
            padding=False
        )

        device = next(_model.parameters()).device
        input_ids = inputs.input_ids.to(device)
        attention_mask = inputs.attention_mask.to(device) if inputs.attention_mask is not None else None

        with torch.no_grad():
            outputs = _model.generate(
                input_ids,
                attention_mask=attention_mask,
                max_new_tokens=60,
                temperature=0.7,
                do_sample=True,
                pad_token_id=_tokenizer.pad_token_id,
                eos_token_id=_tokenizer.eos_token_id, 
                repetition_penalty=1.1,
                no_repeat_ngram_size=3,
                top_p=0.85,
                top_k=30,
                early_stopping=True
            )

        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã
        new_tokens = outputs[0][input_ids.shape[1]:]
        reply = _tokenizer.decode(new_tokens, skip_special_tokens=True).strip()

        # –¢—â–∞—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        cleaned_reply = _clean_reply(reply)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        if (len(cleaned_reply) < 5 or 
            cleaned_reply.count(' ') < 1 or
            all(c in '.,!?;:' for c in cleaned_reply.replace(' ', ''))):
            return "–ú—è—É! –ù–µ –º–æ–≥—É –ø—Ä–∏–¥—É–º–∞—Ç—å —Ö–æ—Ä–æ—à–∏–π –æ—Ç–≤–µ—Ç... –°–ø—Ä–æ—Å–∏ –ø–æ-–¥—Ä—É–≥–æ–º—É! üòø"
        
        return cleaned_reply

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return "–ú—è—É! –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑! üò∫"

def generate_chat_title(first_message: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —á–∞—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    if not _ensure_loaded():
        # Fallback titles when AI is not available
        fallback_titles = [
            "–ß–∞—Ç —Å –ö–æ—Å–º–æ–∫–æ—Ç–æ–º üê±",
            "–ö–æ—Å–º–∏—á–µ—Å–∫–∏–µ –±–µ—Å–µ–¥—ã üöÄ",
            "–ú—è—É-–¥–∏–∞–ª–æ–≥–∏ üí´",
            "–ö–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ üåô",
            "–ó–≤—ë–∑–¥–Ω—ã–π –∫–æ—Ç üêæ",
            "–ö–æ—Å–º–æ–∫–æ—Ç –æ–Ω–ª–∞–π–Ω üõ∞Ô∏è",
            "–ì–∞–ª–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —á–∞—Ç üåå",
            "–ö–æ—Ç–∏–∫ –≤ —Å–∫–∞—Ñ–∞–Ω–¥—Ä–µ üë®‚ÄçüöÄ"
        ]
        return random.choice(fallback_titles)

    try:
        assert _tokenizer is not None and _model is not None
        prompt = _build_title_prompt(first_message)

        inputs = _tokenizer(
            prompt,
            return_tensors="pt",
            padding=False,
            truncation=True,
            max_length=200
        )

        input_ids = inputs.input_ids
        attention_mask = inputs.attention_mask

        with torch.no_grad():
            output = _model.generate(
                input_ids,
                attention_mask=attention_mask,
                max_new_tokens=20,
                temperature=0.8,
                do_sample=True,
                pad_token_id=_tokenizer.pad_token_id,
                eos_token_id=_tokenizer.eos_token_id,
                repetition_penalty=1.2,
                no_repeat_ngram_size=2,
                top_p=0.9,
                top_k=40,
            )

        title = _tokenizer.decode(output[0], skip_special_tokens=True)
        title_start = title.find("–ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞:") + len("–ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞:")
        title = title[title_start:].strip() if title_start != -1 else title.strip()

        # –û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è
        title = re.split(r'[.!?\n]', title)[0].strip()
        title = title[:50]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if not any(char in title for char in ['üê±', 'üêà', 'üöÄ', '‚≠ê', 'üåô', 'üêæ']):
            emojis = ['üê±', 'üêà', 'üöÄ', '‚≠ê', 'üåô', 'üêæ', 'üí´', '‚òÑÔ∏è']
            title += " " + random.choice(emojis)

        return title if title else "–ß–∞—Ç —Å –ö–æ—Å–º–æ–∫–æ—Ç–æ–º üê±"

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
        return "–ß–∞—Ç —Å –ö–æ—Å–º–æ–∫–æ—Ç–æ–º üê±"


def get_random_cat() -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∫–æ—Ç–∞ —Å aleatori.cat"""
    try:
        url = "https://aleatori.cat/random.json"
        resp = requests.get(url, timeout=5)
        resp.raise_for_status()
        data = resp.json()
        
        # –ò–∑ –æ—Ç–≤–µ—Ç–∞ –±–µ—Ä–µ–º –ø–æ–ª–µ "url" —Å JPEG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        cat_url = data.get("url")
        if cat_url:
            return cat_url
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å URL –∫–æ—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞")
            return "https://aleatori.cat/cat"  # fallback URL
            
    except requests.exceptions.Timeout:
        print("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ aleatori.cat")
        return "https://aleatori.cat/cat"
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ aleatori.cat: {e}")
        return "https://aleatori.cat/cat"
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ—Ç–∞: {e}")
        return "https://aleatori.cat/cat"